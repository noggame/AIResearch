
# [LlaMa2](https://github.com/facebookresearch/llama)

- Meta(구 Facebook)에서 최적화된 트랜스포머 아키텍처를 기반으로 만든 자동-회귀 언어 모델
- pre-train 및 fine-tune 진행된 텍스트 모델로, 현재 7B, 13B, 70B 모델을 제공중

## 관련 링크
- 연구 논문 : ["Llama-2: Open Foundation and Fine-tuned Chat Models"](https://huggingface.co/meta-llama/Llama-2-7b/blob/main/arxiv.org/abs/2307.09288)
- [Git](https://github.com/facebookresearch/llama)
- [Huggingface](https://huggingface.co/meta-llama)
- 샘플코드 : [Recipes](https://github.com/facebookresearch/llama-recipes)

> chat 버전의 경우 포맷팅 필요
> - INST 및 <<SYS>> 태그
> - BOS 및 EOS 토큰
> - 문장간 공백 및 시작&끝 지점 공백 제거



## 환경 설정

Windows(WSL2) : https://noggame.tistory.com/72


