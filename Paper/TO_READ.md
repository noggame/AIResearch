[Attention](https://arxiv.org/pdf/1409.0473.pdf)

Transformer : ["Attention is all you need"](https://arxiv.org/pdf/1706.03762.pdf)

gpt 3.0 Technical report
GPT4ALL

[LLaMa](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)

[LlaMa2](https://arxiv.org/pdf/2307.09288.pdf)

LoRA

PEFT
